This is the repository for **YOLO With Caution**, a study in bias mitigation in image detection algorithms. The final code is attached above in Notebooks which you can run yourself.
I encourage you to run the notebook with your own dataset and/or tweak the YOLO algorithm. This months-long research project built YOLO v1 and v7 from the ground up, implemented fairness constraints with the FairLearn package to ensure the demographics of the pedestrians profiled by 
the algorithm were proportionate to U.S. Census data as of 2023, and developed a pipeline for ensuring algorithmic fairness in YOLO-based models through a combination of constraint application and preprocessing techniques.

Open 'YOLO_with_Caution_v1.ipynb' for a full write-up of the research process and code!

Research was conducted from May 31st-August 17th of 2024 under the guidance of [Dr. Raghu Bollapragada](https://oden.utexas.edu/people/directory/Raghu-Bollapragada/) and [Dr. Cem Karamanli](https://www.cemkaramanli.com/)- special thanks to both.

**Paper**:
[https://app.box.com/s/ctkq7f3j5qzmosjh6n79yss2xuqo5qvc](https://app.box.com/s/ctkq7f3j5qzmosjh6n79yss2xuqo5qvc )
**Poster**
[https://app.box.com/s/mbnljke1xvtpxpkfh42o8vio87ir195k](https://app.box.com/s/mbnljke1xvtpxpkfh42o8vio87ir195k)
